# Modelos de OpenAI Disponibles

## üöÄ Modelos GPT-4o (M√°s recientes y potentes)

### 1. **gpt-4o** 
- **Descripci√≥n**: Modelo m√°s reciente y potente de OpenAI (optimizado)
- **Contexto**: 128,000 tokens
- **Costo**: Alto
- **Velocidad**: Muy r√°pido
- **Mejor para**: Tareas complejas, razonamiento avanzado, an√°lisis detallado
- **Fecha de conocimiento**: Octubre 2023

### 2. **gpt-4o-mini** ‚≠ê (RECOMENDADO para uso general)
- **Descripci√≥n**: Versi√≥n optimizada y econ√≥mica de GPT-4o
- **Contexto**: 128,000 tokens
- **Costo**: Muy bajo (15x m√°s barato que gpt-3.5-turbo)
- **Velocidad**: Muy r√°pido
- **Mejor para**: Uso general, excelente relaci√≥n calidad-precio
- **Fecha de conocimiento**: Octubre 2023

## üî• Modelos GPT-4 Turbo

### 3. **gpt-4-turbo**
- **Descripci√≥n**: GPT-4 optimizado para mayor velocidad
- **Contexto**: 128,000 tokens
- **Costo**: Alto
- **Velocidad**: R√°pido
- **Mejor para**: Tareas complejas que requieren mucho contexto
- **Fecha de conocimiento**: Abril 2023

### 4. **gpt-4-turbo-preview**
- **Descripci√≥n**: Versi√≥n preview del GPT-4 Turbo
- **Contexto**: 128,000 tokens
- **Costo**: Alto
- **Velocidad**: R√°pido
- **Mejor para**: Testing de nuevas capacidades

## üéØ Modelos GPT-4 Cl√°sicos

### 5. **gpt-4**
- **Descripci√≥n**: Modelo GPT-4 est√°ndar
- **Contexto**: 8,192 tokens
- **Costo**: Muy alto
- **Velocidad**: Moderado
- **Mejor para**: Tareas que requieren m√°xima precisi√≥n
- **Fecha de conocimiento**: Septiembre 2021

### 6. **gpt-4-32k**
- **Descripci√≥n**: GPT-4 con ventana de contexto extendida
- **Contexto**: 32,768 tokens
- **Costo**: Muy alto
- **Velocidad**: Moderado
- **Mejor para**: An√°lisis de documentos largos

## üí∞ Modelos GPT-3.5 (Econ√≥micos)

### 7. **gpt-3.5-turbo**
- **Descripci√≥n**: Modelo econ√≥mico y r√°pido
- **Contexto**: 16,385 tokens
- **Costo**: Bajo
- **Velocidad**: Muy r√°pido
- **Mejor para**: Tareas simples, chatbots b√°sicos
- **Fecha de conocimiento**: Septiembre 2021

### 8. **gpt-3.5-turbo-16k**
- **Descripci√≥n**: GPT-3.5 con m√°s contexto
- **Contexto**: 16,385 tokens
- **Costo**: Bajo
- **Velocidad**: Muy r√°pido
- **Mejor para**: Conversaciones largas, an√°lisis de texto medio

## üìä Comparativa de Costos (aproximados)

| Modelo | Entrada (por 1M tokens) | Salida (por 1M tokens) | Relaci√≥n calidad/precio |
|--------|-------------------------|------------------------|------------------------|
| gpt-4o | $5.00 | $15.00 | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| gpt-4o-mini | $0.15 | $0.60 | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (MEJOR) |
| gpt-4-turbo | $10.00 | $30.00 | ‚≠ê‚≠ê‚≠ê‚≠ê |
| gpt-4 | $30.00 | $60.00 | ‚≠ê‚≠ê‚≠ê |
| gpt-3.5-turbo | $0.50 | $1.50 | ‚≠ê‚≠ê‚≠ê‚≠ê |

## üé® Recomendaciones por Caso de Uso

### Para tu aplicaci√≥n (an√°lisis de preguntas generales):
```typescript
model: 'gpt-4o-mini' // ‚≠ê MEJOR OPCI√ìN
```
- Excelente calidad de respuestas
- Muy econ√≥mico
- R√°pido
- Contexto grande (128k tokens)

### Para an√°lisis de c√≥digo complejo:
```typescript
model: 'gpt-4o'
```

### Para chatbots simples:
```typescript
model: 'gpt-3.5-turbo'
```

### Para an√°lisis de documentos largos:
```typescript
model: 'gpt-4-turbo'
```

## üîß C√≥mo cambiar el modelo en tu c√≥digo

En `src/modules/ai/ai.service.ts`, l√≠nea ~25:

```typescript
const completion = await this.openai.chat.completions.create({
  model: 'gpt-4o-mini', // üëà Cambia aqu√≠ el modelo
  messages: [...],
  temperature: 0.7,
  max_tokens: 2000,
});
```

## ‚öôÔ∏è Par√°metros adicionales que puedes ajustar:

### Temperature (0.0 - 2.0)
- **0.0-0.3**: Respuestas muy determin√≠sticas y precisas
- **0.7-0.9**: Balance entre creatividad y precisi√≥n (RECOMENDADO)
- **1.0-2.0**: Respuestas muy creativas y variadas

```typescript
temperature: 0.7
```

### Max Tokens
- **100-500**: Respuestas cortas
- **500-1000**: Respuestas medianas
- **1000-2000**: Respuestas detalladas
- **2000-4000**: Respuestas muy extensas

```typescript
max_tokens: 2000
```

### Top P (alternativa a temperature)
```typescript
top_p: 1.0 // 0.1 = m√°s enfocado, 1.0 = m√°s diverso
```

### Frequency Penalty (0.0 - 2.0)
```typescript
frequency_penalty: 0.0 // Penaliza la repetici√≥n de tokens
```

### Presence Penalty (0.0 - 2.0)
```typescript
presence_penalty: 0.0 // Penaliza hablar sobre los mismos temas
```

## üìù Ejemplo de configuraci√≥n avanzada:

```typescript
const completion = await this.openai.chat.completions.create({
  model: 'gpt-4o-mini',
  messages: [
    {
      role: 'system',
      content: 'Eres un experto en TypeScript...',
    },
    {
      role: 'user',
      content: question,
    },
  ],
  temperature: 0.7,
  max_tokens: 2000,
  top_p: 1.0,
  frequency_penalty: 0.0,
  presence_penalty: 0.0,
});
```

## üåê Modelos especializados adicionales:

### Para visi√≥n (im√°genes):
- `gpt-4o` - Puede analizar im√°genes
- `gpt-4-vision-preview` - Preview con capacidades de visi√≥n

### Para embeddings (b√∫squeda sem√°ntica):
- `text-embedding-3-large`
- `text-embedding-3-small`
- `text-embedding-ada-002`

### Para audio (transcripci√≥n):
- `whisper-1`

### Para generaci√≥n de im√°genes:
- `dall-e-3`
- `dall-e-2`

## üí° Consejo Final

Para tu caso de uso actual, **`gpt-4o-mini`** es la mejor opci√≥n:
- ‚úÖ Respuestas de alta calidad
- ‚úÖ Muy econ√≥mico (15x m√°s barato que gpt-3.5-turbo)
- ‚úÖ R√°pido
- ‚úÖ Gran ventana de contexto
- ‚úÖ Conocimiento actualizado hasta Oct 2023
